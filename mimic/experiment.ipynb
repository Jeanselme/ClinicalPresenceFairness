{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook runs the model on the preprocessed data. The goal is to predict if the patient will survive to its stay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reload data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labs = pd.read_csv('data/labs_1_day.csv', index_col = [0, 1], header = [0, 1])\n",
    "outcomes = pd.read_csv('data/outcomes_1_day.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes['Death'] = outcomes['Death'] < 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = outcomes[['ETHNICITY', 'GENDER', 'INSURANCE']]\n",
    "groups.ETHNICITY = outcomes.ETHNICITY.str.contains('BLACK')\n",
    "groups.GENDER = (outcomes.ETHNICITY == 'M')\n",
    "groups.INSURANCE = (outcomes.INSURANCE == 'Private')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results path\n",
    "results = 'results/classification' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.Series(outcomes.index.isin(outcomes.sample(frac = 0.8, random_state = 0).index), index = outcomes.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total patients: {}'.format(len(training)))\n",
    "print('Training patients: {}'.format(training.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "def imputation(train_index, data, groups, strategy = 'Median', add_count = False, add_group = False, max_iter = 10):\n",
    "    imputed = data.add_suffix('_data').groupby('Patient').last()\n",
    "\n",
    "    if add_count:\n",
    "        # Add count of observed test\n",
    "        imputed = pd.concat([imputed, (imputed.isna()).add_suffix('_count')], axis = 1)\n",
    "\n",
    "    if add_group:\n",
    "        # Add group\n",
    "        imputed = imputed.join(groups.add_suffix('_group'))\n",
    "\n",
    "    if 'Group' in strategy:\n",
    "        # Add group befoer splitting only for imputation\n",
    "        imputed = imputed.join(groups.add_suffix('_group_reg'))\n",
    "\n",
    "    # Data to use to learn imputation\n",
    "    train_data = imputed.loc[imputed.index.get_level_values('Patient').isin(train_index)]\n",
    "    train_index = train_data.index\n",
    "    \n",
    "    # Compute fill value\n",
    "    if strategy == 'LOCF':\n",
    "        imputed = imputed.groupby('Patient').ffill()\n",
    "        impute = - 1\n",
    "\n",
    "    if strategy == 'Individual':\n",
    "        impute = imputed.groupby('Patient').median()\n",
    "        \n",
    "    if strategy == 'Median':\n",
    "        impute = train_data.median()\n",
    "\n",
    "    if strategy == 'Mean':\n",
    "        impute = train_data.mean()\n",
    "\n",
    "    if strategy == 'Group Median':\n",
    "        impute = train_data.groupby(groups).transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "    if strategy == 'Group Mean':\n",
    "        impute = train_data.groupby(groups).transform(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "    if 'MICE' in strategy:\n",
    "        impute = -1\n",
    "\n",
    "        # MICE Algorithm\n",
    "        ## 1. Init with median imputation\n",
    "        missing = imputed.isna()\n",
    "        imputed = pd.DataFrame(SimpleImputer(strategy = \"median\").fit(train_data.values).transform(imputed.values), index = imputed.index, columns = imputed.columns)\n",
    "\n",
    "        ## 2. Iterate through columns\n",
    "        ### Find columns with random values (start with the one with least)\n",
    "        to_impute = missing.sum().sort_values()\n",
    "        to_impute = to_impute[to_impute > 0]\n",
    "\n",
    "        ### Impute one by one with regression until convergence\n",
    "        for _ in range(max_iter):\n",
    "            for c in to_impute.index:\n",
    "                #### Take train points for which c is observed to train model\n",
    "                train_data = imputed.loc[train_index][~missing.loc[train_index][c]]\n",
    "\n",
    "                #### Fit regression\n",
    "                lr = LinearRegression().fit(train_data.loc[:, imputed.columns != c].values, train_data[c].values)\n",
    "                residuals = np.abs(lr.predict(train_data.loc[:, imputed.columns != c].values) - train_data[c])\n",
    "\n",
    "                #### Draw with normal error\n",
    "                prev = imputed.copy()\n",
    "                imputed[c][missing[c]] = lr.predict(imputed.loc[:, imputed.columns != c][missing[c]].values) + np.random.normal(scale = np.std(residuals), size = missing[c].sum())\n",
    "        else:\n",
    "            if 'Group' in strategy:\n",
    "                # Remove the group columns of imputed data\n",
    "                imputed = imputed.iloc[:, :-1]\n",
    "\n",
    "    return imputed, impute\n",
    "\n",
    "\n",
    "def process(train_index, data, groups, **args):\n",
    "    \"\"\"\n",
    "        Preprocesses data \n",
    "        Take last observation and impute given strategy\n",
    "    \"\"\"\n",
    "    updated, impute = imputation(train_index, data, groups, **args)\n",
    "    #resampled = updated.groupby('Patient').last()\n",
    "    imputed = updated.fillna(impute)\n",
    "\n",
    "    return imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = {\n",
    "    'penalty': ['l2'],\n",
    "    'C': [0.01, 0.1, 1., 10],\n",
    "    'solver': ['sag'], \n",
    "    'max_iter': [1000],\n",
    "    'n_jobs': [-1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputations = {\n",
    "                #'Median': {'strategy': 'Median'},\n",
    "                'Median Missing': {'strategy': 'Median', 'add_count': True},\n",
    "                #'MICE': {'strategy': 'MICE', 'n_iter': 10},\n",
    "                'MICE Missing': {'strategy': 'MICE', 'n_iter': 10, 'add_count': True},\n",
    "                #'Group MICE': {'strategy': 'Group MICE', 'n_iter': 10},\n",
    "                #'Group MICE Missing': {'strategy': 'Group MICE', 'n_iter': 10, 'add_count': True},\n",
    "                #'Individual': {'strategy': 'Individual'},\n",
    "                #'LOCF': {'strategy': 'LOCF'},\n",
    "                #'LOCF Count': {'strategy': 'LOCF', 'add_count': True},\n",
    "                #'LOCF Group': {'strategy': 'LOCF', 'add_count': True, 'add_group': True},\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, params in imputations.items():\n",
    "    print('Imputation strategy: ', name)\n",
    "    n_iter = params.pop('n_iter', 1)\n",
    "\n",
    "    predictions = []\n",
    "    for iter in range(n_iter):\n",
    "        last = process(training[training].index, labs, groups, **params)\n",
    "        assert (last == -1).sum().sum() == 0, \"Non imputed values\"\n",
    "\n",
    "        se = Experiment.create(model = 'log', hyper_grid = hyperparams, save = False, path = results + name)\n",
    "        pred = se.train(last, outcomes.Death, training)\n",
    "        if pred is None: break # Reload previous copy\n",
    "        predictions.append(pred)\n",
    "    else:\n",
    "        # Average Multiple imputations models\n",
    "        used = [p.Use for p in predictions][-1]\n",
    "        predictions = pd.concat([p[1] for p in predictions], axis = 1)\n",
    "        predictions = pd.concat({'Mean': predictions.mean(1), 'Std': predictions.std(1)}, axis = 1)\n",
    "        se = Experiment.create(model = 'log', hyper_grid = hyperparams, path = results + name)\n",
    "        se.save_results(predictions, used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a54f3b3a447186e9a4a83057d2abe8df010acd7b8f131225203d307ef84eba48"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('Jupyter': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (default, Sep 16 2021, 13:09:58) \n[GCC 7.5.0]"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
