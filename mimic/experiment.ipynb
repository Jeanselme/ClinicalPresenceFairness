{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook runs the model on the preprocessed data. The goal is to predict if the patient will survive to its stay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reload data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labs = pd.read_csv('data/labs_1_day.csv', index_col = [0, 1], header = [0, 1])\n",
    "outcomes = pd.read_csv('data/outcomes_1_day.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes['Death'] = outcomes['Death'] < 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = outcomes[['ETHNICITY', 'GENDER', 'INSURANCE']]\n",
    "groups.ETHNICITY = outcomes.ETHNICITY.str.contains('BLACK')\n",
    "groups.GENDER = (outcomes.ETHNICITY == 'M')\n",
    "groups.INSURANCE = (outcomes.INSURANCE == 'Private')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results path\n",
    "results = 'results/classification' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.Series(outcomes.index.isin(outcomes.sample(frac = 0.8, random_state = 0).index), index = outcomes.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total patients: {}'.format(len(training)))\n",
    "print('Training patients: {}'.format(training.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "def imputation(train_index, data, groups, strategy = 'Median', add_missingness = False, max_iter = 10):\n",
    "    imputed = data.add_suffix('_data').groupby('Patient').ffill().groupby('Patient').last() # Latest test\n",
    "\n",
    "    if add_missingness:\n",
    "        imputed = imputed.join(imputed.isna().add_suffix('_missing'))\n",
    "\n",
    "    # Data to use to learn imputation\n",
    "    train_data = imputed.loc[imputed.index.get_level_values('Patient').isin(train_index)]\n",
    "    train_index = train_data.index\n",
    "    \n",
    "    # Compute fill value\n",
    "    impute = train_data.mean()\n",
    "    if strategy == 'Mean':\n",
    "        imputed = imputed.transform(lambda x: x.fillna(impute[x.name]))\n",
    "\n",
    "    if strategy == 'Group Mean':\n",
    "        mean_group = train_data.groupby(groups.loc[train_index]).mean()\n",
    "        imputed = imputed.groupby(groups).transform(lambda x: x.fillna(mean_group.loc[groups.loc[x.index[0]]][x.name]))\n",
    "        imputed = imputed.transform(lambda x: x.fillna(impute[x.name])) # Replace any missing data\n",
    "\n",
    "    if 'MICE' in strategy:\n",
    "        if 'Group' in strategy:\n",
    "            # Add group befoer splitting only for imputation\n",
    "            imputed = imputed.join(groups)\n",
    "            train_data = imputed.loc[train_index]\n",
    "        # MICE Algorithm\n",
    "        ## 1. Init with median imputation\n",
    "        missing = imputed.isna()\n",
    "        imputed = pd.DataFrame(SimpleImputer(strategy = \"mean\").fit(train_data.values).transform(imputed.values), index = imputed.index, columns = imputed.columns)\n",
    "\n",
    "        ## 2. Iterate through columns\n",
    "        ### Find columns with random values (start with the one with least)\n",
    "        to_impute = missing.sum().sort_values()\n",
    "        to_impute = to_impute[to_impute > 0]\n",
    "\n",
    "        ### Impute one by one with regression until convergence\n",
    "        for _ in range(max_iter):\n",
    "            for c in to_impute.index:\n",
    "                #### Take train points for which c is observed to train model\n",
    "                train_data = imputed.loc[train_index][~missing.loc[train_index][c]]\n",
    "\n",
    "                #### Fit regression\n",
    "                lr = LinearRegression().fit(train_data.loc[:, imputed.columns != c].values, train_data[c].values)\n",
    "                residuals = np.abs(lr.predict(train_data.loc[:, imputed.columns != c].values) - train_data[c])\n",
    "\n",
    "                #### Draw with normal error\n",
    "                prev = imputed.copy()\n",
    "                imputed[c][missing[c]] = lr.predict(imputed.loc[:, imputed.columns != c][missing[c]].values) + np.random.normal(scale = np.std(residuals), size = missing[c].sum())\n",
    "        if 'Group' in strategy:\n",
    "            # Remove the group columns of imputed data\n",
    "            imputed = imputed.iloc[:, :-1]\n",
    "\n",
    "    return imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = {\n",
    "    'penalty': ['l2'],\n",
    "    'C': [0.01, 0.1, 1., 10],\n",
    "    'solver': ['sag'], \n",
    "    'max_iter': [1000],\n",
    "    'n_jobs': [-1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputations = {\n",
    "                'Mean': {'strategy': 'Mean'},\n",
    "                'Mean Missing': {'strategy': 'Mean', 'add_missingness': True},\n",
    "\n",
    "                'Group Ethnicity Mean': {'strategy': 'Group Mean', 'group': groups.ETHNICITY},\n",
    "                'Group Sex Mean': {'strategy': 'Group Mean', 'group': groups.GENDER},\n",
    "                'Group Insurance Mean': {'strategy': 'Group Mean', 'group': groups.INSURANCE},\n",
    "\n",
    "                'Group Ethnicity Mean Missing': {'strategy': 'Group Mean', 'group': groups.ETHNICITY, 'add_missingness': True},\n",
    "                'Group Sex Mean Missing': {'strategy': 'Group Mean', 'group': groups.GENDER, 'add_missingness': True},\n",
    "                'Group Insurance Mean Missing': {'strategy': 'Group Mean', 'group': groups.INSURANCE, 'add_missingness': True},\n",
    "\n",
    "                'MICE': {'strategy': 'MICE', 'n_iter': 10},\n",
    "                'MICE Missing': {'strategy': 'MICE', 'n_iter': 10, 'add_missingness': True},\n",
    "\n",
    "                'Group Ethnicity MICE': {'strategy': 'Group MICE', 'n_iter': 10, 'group': groups.ETHNICITY},\n",
    "                'Group Sex MICE': {'strategy': 'Group MICE', 'n_iter': 10, 'group': groups.GENDER},\n",
    "                'Group Insurance MICE': {'strategy': 'Group MICE', 'n_iter': 10, 'group': groups.INSURANCE},\n",
    "\n",
    "                'Group Ethnicity MICE Missing': {'strategy': 'Group MICE', 'n_iter': 10, 'group': groups.ETHNICITY, 'add_missingness': True},\n",
    "                'Group Sex MICE Missing': {'strategy': 'Group MICE', 'n_iter': 10, 'group': groups.GENDER, 'add_missingness': True},\n",
    "                'Group Insurance MICE Missing': {'strategy': 'Group MICE', 'n_iter': 10, 'group': groups.INSURANCE, 'add_missingness': True},\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, params in imputations.items():\n",
    "    print('Imputation strategy: ', name)\n",
    "    n_iter = params.pop('n_iter', 1)\n",
    "    subgroup = params.pop('group', groups)\n",
    "\n",
    "    predictions = []\n",
    "    for iter in range(n_iter):\n",
    "        last = imputation(training[training].index, labs, subgroup, **params)\n",
    "        assert (last == -1).sum().sum() == 0, \"Non imputed values\"\n",
    "\n",
    "        se = Experiment.create(model = 'log', hyper_grid = hyperparams, save = False, path = results + name)\n",
    "        pred = se.train(last, outcomes.Death, training)\n",
    "        if pred is None: break # Reload previous copy\n",
    "        predictions.append(pred)\n",
    "    else:\n",
    "        # Average Multiple imputations models\n",
    "        used = [p.Use for p in predictions][-1]\n",
    "        predictions = pd.concat([p[1] for p in predictions], axis = 1)\n",
    "        predictions = pd.concat({'Mean': predictions.mean(1), 'Std': predictions.std(1)}, axis = 1)\n",
    "        se = Experiment.create(model = 'log', hyper_grid = hyperparams, path = results + name)\n",
    "        se.save_results(predictions, used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "survival",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10 | packaged by conda-forge | (main, Mar 24 2023, 20:12:31) [Clang 14.0.6 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "f1b50223f39b64c0c24545f474e3e7d2d3b4b121fe045100fc03a3926bb649af"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
